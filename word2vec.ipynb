{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sundarayamrita/NLP/blob/master/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biewLipZblwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jXzS6LuKuVlV",
        "colab": {}
      },
      "source": [
        "corpus = open('WarAndPeace.txt', 'rb').read().decode(encoding='utf-8')[1:]\n",
        "corpus = corpus.replace(',', ' ')\n",
        "corpus = corpus.replace('\\\"', ' ')\n",
        "corpus = corpus.replace('!', '.')\n",
        "corpus = corpus.replace('?', '.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i39efQCWBSB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def sentence_tokeniser(corpus):\n",
        "  return list(corpus[7424:].split('.'))\n",
        "\n",
        "sentences = sentence_tokeniser(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxidn4UzWlL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_corpus(sentences):\n",
        "    tokens = [x.split() for x in sentences]\n",
        "    return tokens\n",
        "\n",
        "tokenized_corpus = tokenize_corpus(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WUM0AKoX5Lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = []\n",
        "for sentence in tokenized_corpus:\n",
        "    for token in sentence:\n",
        "        if token not in vocabulary:\n",
        "            vocabulary.append(token)\n",
        "\n",
        "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
        "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
        "\n",
        "vocabulary_size = len(vocabulary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwtibccuq5PF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "window_size = 2\n",
        "idx_pairs = []\n",
        "for sentence in tokenized_corpus:\n",
        "    indices = [word2idx[word] for word in sentence]\n",
        "    for center_word_pos in range(len(indices)):\n",
        "        for w in range(-window_size, window_size + 1):\n",
        "            context_word_pos = center_word_pos + w\n",
        "            if context_word_pos < 0 or context_word_pos >= len(indices) or center_word_pos == context_word_pos:\n",
        "                continue\n",
        "            context_word_idx = indices[context_word_pos]\n",
        "            idx_pairs.append((indices[center_word_pos], context_word_idx))\n",
        "\n",
        "idx_pairs = torch.from_numpy(np.array(idx_pairs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYO_A96Ram0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_input_layer(word_idx):\n",
        "    x = torch.zeros(vocabulary_size).float()\n",
        "    x[word_idx] = 1.0\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27D5sUSKaHkC",
        "colab_type": "code",
        "outputId": "4bd52447-1ef1-4419-a62d-22ab1fc5cb8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "embedding_dims = 300\n",
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "W_target = Variable(torch.randn(embedding_dims, vocabulary_size).float(), requires_grad=True)\n",
        "W_context = Variable(torch.randn(vocabulary_size, embedding_dims).float(), requires_grad=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    loss_val = 0\n",
        "    for data, target in idx_pairs:\n",
        "        x = Variable(get_input_layer(data)).float()\n",
        "        y_true = Variable(torch.from_numpy(np.array([target])).long())\n",
        "\n",
        "        z1 = torch.matmul(W_target, x)\n",
        "        z2 = torch.matmul(W_context, z1)\n",
        "    \n",
        "        log_softmax = F.log_softmax(z2, dim=0)\n",
        "\n",
        "        loss = F.nll_loss(log_softmax.view(1,-1), y_true)\n",
        "        loss_val += loss.data[0]\n",
        "        loss.backward()\n",
        "        W_target.data -= learning_rate * W_target.grad.data\n",
        "        W_context.data -= learning_rate * W_context.grad.data\n",
        "\n",
        "        W_target.grad.data.zero_()\n",
        "        W_context.grad.data.zero_()\n",
        "    if epo % 10 == 0:    \n",
        "        print(f'Loss at epo {epo}: {loss_val/len(idx_pairs)}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-6c148447f969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss_val\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mW_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wLmoyZD2LIv",
        "colab_type": "text"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
        "        # kernel\n",
        "        # self.conv1 = nn.Conv2d(1, 6, 3)\n",
        "        # self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.W_word = Variable(torch.randn(embedding_dims, vocabulary_size).float(), requires_grad=True)\n",
        "        self.W_context = Variable(torch.randn(vocabulary_size, embedding_dims).float(), requires_grad=True)\n",
        "        #self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        #x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        #x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        h = F.(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ]
    }
  ]
}